{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e69974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('../utils/'))))\n",
    "from utils.preprocess_utils import save_cache\n",
    "data_path = '/data1/jyhwang/SR/'\n",
    "file_name = 'Books.csv'\n",
    "df = pd.read_csv(data_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085a5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view_org = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2438ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1446304000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1564770672</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1442450703</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1523093714024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1780671067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1611623223325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1645671127</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1612044209266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488292</th>\n",
       "      <td>AGZ44L7OCCLE76RJOZ3VGKOEKLFQ</td>\n",
       "      <td>0743259823</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1102914217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488293</th>\n",
       "      <td>AGZ44L7OCCLE76RJOZ3VGKOEKLFQ</td>\n",
       "      <td>0891230513</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1102921345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488294</th>\n",
       "      <td>AGZ44L7OCCLE76RJOZ3VGKOEKLFQ</td>\n",
       "      <td>0891230483</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1102921945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488295</th>\n",
       "      <td>AGZ44L7OCCLE76RJOZ3VGKOEKLFQ</td>\n",
       "      <td>0500016909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1103970985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488296</th>\n",
       "      <td>AGZ44L7OCCLE76RJOZ3VGKOEKLFQ</td>\n",
       "      <td>0890963908</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1103974463000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9488297 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              user_id parent_asin  rating      timestamp\n",
       "0        AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1446304000     5.0  1441260345000\n",
       "1        AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1564770672     5.0  1441260365000\n",
       "2        AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1442450703     5.0  1523093714024\n",
       "3        AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1780671067     1.0  1611623223325\n",
       "4        AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1645671127     3.0  1612044209266\n",
       "...                               ...         ...     ...            ...\n",
       "9488292  AGZ44L7OCCLE76RJOZ3VGKOEKLFQ  0743259823     4.0  1102914217000\n",
       "9488293  AGZ44L7OCCLE76RJOZ3VGKOEKLFQ  0891230513     3.0  1102921345000\n",
       "9488294  AGZ44L7OCCLE76RJOZ3VGKOEKLFQ  0891230483     3.0  1102921945000\n",
       "9488295  AGZ44L7OCCLE76RJOZ3VGKOEKLFQ  0500016909     2.0  1103970985000\n",
       "9488296  AGZ44L7OCCLE76RJOZ3VGKOEKLFQ  0890963908     5.0  1103974463000\n",
       "\n",
       "[9488297 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736e828",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a63d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1577808061000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_view = df_view_org\n",
    "# 2020. 01. 1 부터..\n",
    "filtered_df = df_view[df_view.timestamp>1577808061000]\n",
    "# 2017. 01. 0.1\n",
    "1483196400000\n",
    "# 2020. 0.1 01\n",
    "1577808061000\n",
    "#filtered_df = df_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae47fa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Filtering\n",
      "1634099\n",
      "User Filtering\n",
      "1201417\n"
     ]
    }
   ],
   "source": [
    "# User-Item Filtering\n",
    "item_filter = (filtered_df['parent_asin'].value_counts() >= 5)\n",
    "filtered_items = filtered_df['parent_asin'].value_counts()[item_filter].index\n",
    "\n",
    "print(\"Item Filtering\")\n",
    "print(len(filtered_df))\n",
    "\n",
    "user_filter = (filtered_df['user_id'].value_counts() >= 5)\n",
    "filtered_users = filtered_df['user_id'].value_counts()[user_filter].index\n",
    "filtered_df = filtered_df[filtered_df['user_id'].isin(filtered_users)]\n",
    "\n",
    "print(\"User Filtering\")\n",
    "print(len(filtered_df))\n",
    "\n",
    "# Extract interactions for model training (numpy.ndarray)\n",
    "uit = filtered_df.loc[:, ['user_id', 'parent_asin', 'timestamp'] ].values\n",
    "ust = filtered_df.loc[:, ['user_id', 'parent_asin', 'timestamp'] ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab972254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess_utils import map_feature_id\n",
    "num_users,uid_map,uid_rmap = map_feature_id(uit[:,0], str, int)\n",
    "num_items,iid_map,iid_rmap = map_feature_id(uit[:,1], str, int)\n",
    "num_time,tid_map,tid_rmap = map_feature_id(sorted(uit[:,2]), str, int) #The mapped timeid should be sorted,\n",
    "num_state,sid_map,sid_rmap = map_feature_id(ust[:,1], str, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "008f7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess_utils import build_seq_list\n",
    "raw_sequences = build_seq_list(uit, uid_map, iid_map, tid_map)#\n",
    "#raw_state_sequences= build_seq_list(ust, uid_map, sid_map, tid_map)\n",
    "from utils.preprocess_utils import remove_redundant_items\n",
    "item_sequences = remove_redundant_items(raw_sequences, raw_sequences)\n",
    "#state_sequences= remove_redundant_items(raw_state_sequences, raw_state_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51890387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess_utils import split_seqs\n",
    "'''\n",
    "For debugging code.\n",
    "\n",
    "item_sequences = [[1, 2, 3, 4, 5, 6, 7],\n",
    "                  [1, 3, 5, 7, 9, 11,1],\n",
    "                  [2, 4, 2, 6, 8, 9, 4]]\n",
    "\n",
    "'''\n",
    "train_seqs, valid_test_seqs = split_seqs(item_sequences,0.8)\n",
    "valid_seqs, test_seqs = split_seqs(valid_test_seqs,0.5)\n",
    "\n",
    "from utils.preprocess_utils import extract_valid_seqs\n",
    "train_valid_seqs = list(map(lambda seq: seq[0] + seq[1],\n",
    "                            zip(train_seqs,valid_seqs)))\n",
    "\n",
    "valid_seqs, valid_items = extract_valid_seqs(train_seqs, valid_seqs)\n",
    "test_seqs, test_items = extract_valid_seqs(train_valid_seqs, test_seqs)\n",
    "'''\n",
    "For debugging code.\n",
    "\n",
    "print(train_seqs)\n",
    "print(train_valid_seqs)\n",
    "print(\"Validation \")\n",
    "print(valid_seqs)\n",
    "print(valid_items)\n",
    "print(\"Testing\")\n",
    "print(test_seqs)\n",
    "print(test_items)\n",
    "'''\n",
    "\n",
    "from utils.preprocess_utils import generate_pairs_from_sequences\n",
    "from scipy.sparse import csr_matrix\n",
    "valid_seen_pairs = np.array(list(generate_pairs_from_sequences(valid_seqs)))\n",
    "valid_seen_vals = np.ones(len(valid_seen_pairs))\n",
    "valid_seen_rows = valid_seen_pairs[:,0]\n",
    "valid_seen_cols = valid_seen_pairs[:,1]\n",
    "valid_seen_mat = csr_matrix((valid_seen_vals,\n",
    "                            (valid_seen_rows,\n",
    "                             valid_seen_cols)), shape = (num_users,num_items))\n",
    "\n",
    "\n",
    "valid_unseen_pairs = np.array(list(generate_pairs_from_sequences(valid_items)))\n",
    "valid_unseen_vals = np.ones(len(valid_unseen_pairs))\n",
    "valid_unseen_rows = valid_unseen_pairs[:,0]\n",
    "valid_unseen_cols = valid_unseen_pairs[:,1]\n",
    "valid_unseen_mat = csr_matrix((valid_unseen_vals,\n",
    "                            (valid_unseen_rows,\n",
    "                             valid_unseen_cols)), shape = (num_users,num_items))\n",
    "\n",
    "\n",
    "test_seen_pairs = np.array(list(generate_pairs_from_sequences(test_seqs)))\n",
    "test_seen_vals = np.ones(len(test_seen_pairs))\n",
    "test_seen_rows = test_seen_pairs[:,0]\n",
    "test_seen_cols = test_seen_pairs[:,1]\n",
    "test_seen_mat = csr_matrix((test_seen_vals,\n",
    "                            (test_seen_rows,\n",
    "                             test_seen_cols)), shape = (num_users,num_items))\n",
    "\n",
    "\n",
    "test_unseen_pairs = np.array(list(generate_pairs_from_sequences(test_items)))\n",
    "test_unseen_vals = np.ones(len(test_unseen_pairs))\n",
    "test_unseen_rows = test_unseen_pairs[:,0]\n",
    "test_unseen_cols = test_unseen_pairs[:,1]\n",
    "test_unseen_mat = csr_matrix((test_unseen_vals,\n",
    "                             (test_unseen_rows,\n",
    "                             test_unseen_cols)), shape = (num_users,num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ab4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pos_lists = [sorted(items) for items in train_seqs] # For efficient negative sampling in training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d744ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users:97238 num_items:195053\n"
     ]
    }
   ],
   "source": [
    "print(\"num_users:%s num_items:%s\"%(num_users,num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164723a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess_utils import save_cache\n",
    "objs = {\n",
    "    \"num_users\": num_users,\n",
    "    \"num_items\": num_items,\n",
    "    \"train_seqs\": train_seqs,\n",
    "    \"valid_seqs\": valid_seqs,\n",
    "    \"test_seqs\": test_seqs,\n",
    "    \"valid_seen_mat\": valid_seen_mat,\n",
    "    \"valid_gt_mat\": valid_unseen_mat,\n",
    "    \"test_seen_mat\": test_seen_mat,\n",
    "    \"test_gt_mat\": test_unseen_mat,\n",
    "    \"sorted_pos_lists\": sorted_pos_lists\n",
    "}\n",
    "save_cache(data_path,'Books_cache',objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c696f7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,     9],\n",
       "       [    2,    30],\n",
       "       [    3,    63],\n",
       "       ...,\n",
       "       [42766, 36943],\n",
       "       [42767, 52222],\n",
       "       [42768, 51575]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_unseen_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46b25728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4106d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bbd23cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c6321d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFWHJ6O3PV4JC7PVOJH6CPULO2KQ</td>\n",
       "      <td>B000002AGY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1358286606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFWHJ6O3PV4JC7PVOJH6CPULO2KQ</td>\n",
       "      <td>B002HMHR7S</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1402778050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFWHJ6O3PV4JC7PVOJH6CPULO2KQ</td>\n",
       "      <td>B0000062P5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1504898965457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFWHJ6O3PV4JC7PVOJH6CPULO2KQ</td>\n",
       "      <td>B00004NKAK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1524768111415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFWHJ6O3PV4JC7PVOJH6CPULO2KQ</td>\n",
       "      <td>B07Z76Y18X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1576100171173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552759</th>\n",
       "      <td>AHHXVAEKAYJGVWACMYCSBQUND7TQ</td>\n",
       "      <td>B000002HQ3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1004132347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552760</th>\n",
       "      <td>AHHXVAEKAYJGVWACMYCSBQUND7TQ</td>\n",
       "      <td>B000002KHH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1011831232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552761</th>\n",
       "      <td>AHHXVAEKAYJGVWACMYCSBQUND7TQ</td>\n",
       "      <td>B00004Y6O6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1012932465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552762</th>\n",
       "      <td>AHHXVAEKAYJGVWACMYCSBQUND7TQ</td>\n",
       "      <td>B00000AGAS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1020810521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552763</th>\n",
       "      <td>AHHXVAEKAYJGVWACMYCSBQUND7TQ</td>\n",
       "      <td>B00008OX4R</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1053559409000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552764 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              user_id parent_asin  rating      timestamp\n",
       "0        AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  B000002AGY     5.0  1358286606000\n",
       "1        AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  B002HMHR7S     4.0  1402778050000\n",
       "2        AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  B0000062P5     5.0  1504898965457\n",
       "3        AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  B00004NKAK     5.0  1524768111415\n",
       "4        AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  B07Z76Y18X     5.0  1576100171173\n",
       "...                               ...         ...     ...            ...\n",
       "1552759  AHHXVAEKAYJGVWACMYCSBQUND7TQ  B000002HQ3     5.0  1004132347000\n",
       "1552760  AHHXVAEKAYJGVWACMYCSBQUND7TQ  B000002KHH     5.0  1011831232000\n",
       "1552761  AHHXVAEKAYJGVWACMYCSBQUND7TQ  B00004Y6O6     4.0  1012932465000\n",
       "1552762  AHHXVAEKAYJGVWACMYCSBQUND7TQ  B00000AGAS     5.0  1020810521000\n",
       "1552763  AHHXVAEKAYJGVWACMYCSBQUND7TQ  B00008OX4R     2.0  1053559409000\n",
       "\n",
       "[1552764 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad17dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문제의 코드\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def _get_recall(batch_hits, num_tests, cond):\n",
    "\n",
    "    return batch_hits.sum(1,keepdims=True)[cond]/(num_tests)[cond]\n",
    "\n",
    "def _get_ndcg(batch_hits, num_tests, cond):\n",
    "    \n",
    "    topk = batch_hits.size(1)\n",
    "    denominator = torch.log2(1+torch.arange(1,topk+1)).unsqueeze(0).cuda()\n",
    "    DCG_K = (batch_hits/denominator)[cond]\n",
    "    \n",
    "    IDCG_K = torch.cumsum((1./denominator),1).flatten()\n",
    "    \n",
    "    IDCG_I = num_tests[cond].flatten().long() -1\n",
    "    IDCG_I[IDCG_I>=topk] = topk-1\n",
    "    \n",
    "    norm = IDCG_K[IDCG_I].unsqueeze(1)\n",
    "    \n",
    "    NDCG_K = (DCG_K).sum(1,keepdims=True)/norm\n",
    "    \n",
    "    return NDCG_K\n",
    "    \n",
    "def _get_rr(batch_hits, cond):\n",
    "    denominator = (1.0 / torch.arange(1, batch_hits.size(1) + 1)).cuda()\n",
    "    denominator = denominator.unsqueeze(0)\n",
    "\n",
    "    # rr is reciprocal rank\n",
    "    rr = ((batch_hits >= 1.0) * denominator * batch_hits)[cond]\n",
    "    rr = torch.max(rr, 1).values\n",
    "\n",
    "    return rr\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate_topk(model, seq_list, dataset, scenario = 'valid', topk = 20):\n",
    "\n",
    "    '''\n",
    "     evaluate topk ranking performance\n",
    "     (currently, only recall is implemented)\n",
    "     \n",
    "     :param model: recommender system\n",
    "     :param list seq_list: user list for test\n",
    "     :param dataset: dataset\n",
    "     :param int topk: # of items to show\n",
    "     \"\n",
    "    '''\n",
    "    \n",
    "    model.eval()\n",
    "    if scenario == 'valid':\n",
    "        coo = dataset.valid_seen_mat.tocoo()       \n",
    "        ind = torch.LongTensor([coo.row.tolist(), coo.col.tolist()])\n",
    "        val = torch.LongTensor(coo.data.astype(np.int32))\n",
    "        seen_mat = torch.sparse_coo_tensor(ind, val, (dataset.num_seqs, dataset.num_items)).cuda()\n",
    "        \n",
    "        coo = dataset.valid_gt_mat.tocoo()\n",
    "        ind = torch.LongTensor([coo.row.tolist(), coo.col.tolist()])\n",
    "        val = torch.LongTensor(coo.data.astype(np.int32))\n",
    "        gt_mat = torch.sparse_coo_tensor(ind, val, (dataset.num_seqs, dataset.num_items)).cuda()\n",
    "        \n",
    "        last_subseqs = torch.LongTensor(dataset.valid_last_subseqs[:,1:]).cuda()\n",
    "    if scenario == 'test':\n",
    "        coo = dataset.test_seen_mat.tocoo()\n",
    "        ind = torch.LongTensor([coo.row.tolist(), coo.col.tolist()])\n",
    "        val = torch.LongTensor(coo.data.astype(np.int32))\n",
    "        seen_mat = torch.sparse_coo_tensor(ind, val, (dataset.num_seqs, dataset.num_items)).cuda()\n",
    "        \n",
    "        coo = dataset.test_gt_mat.tocoo()\n",
    "        ind = torch.LongTensor([coo.row.tolist(), coo.col.tolist()])\n",
    "        val = torch.LongTensor(coo.data.astype(np.int32))\n",
    "        gt_mat = torch.sparse_coo_tensor(ind, val, (dataset.num_seqs, dataset.num_items)).cuda()\n",
    "        #check last subseqs\n",
    "        last_subseqs = torch.LongTensor(dataset.test_last_subseqs[:,1:]).cuda()\n",
    "    \n",
    "    #prepare sequences\n",
    "    seq_indices = torch.split(torch.LongTensor(seq_list),256)\n",
    "    all_item_indices = torch.arange(dataset.num_items).unsqueeze(1).cuda()\n",
    "    \n",
    "    recall = torch.cuda.DoubleTensor()\n",
    "    ndcg = torch.cuda.DoubleTensor()\n",
    "    mrr = torch.cuda.DoubleTensor()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch_seq_indices in enumerate(tqdm(seq_indices, desc=\"Evaluation\", disable = True)):\n",
    "            batch_seq_indices = batch_seq_indices.cuda()\n",
    "            batch_scores = torch.zeros( (len(batch_seq_indices), dataset.num_items)).cuda()\n",
    "            predicted_scores = model(batch_seq_indices,\n",
    "                                     last_subseqs[batch_seq_indices],\n",
    "                                     all_item_indices, # NX1\n",
    "                                     pred_opt='eval')\n",
    "            #print(predicted_scores)\n",
    "            #breakpoint()\n",
    "            batch_seen_array = torch.index_select(seen_mat, 0, batch_seq_indices).to_dense()\n",
    "            batch_scores.unsqueeze(0)[:, batch_seen_array > 0 ] = -1000.0 # ignore seen items\n",
    "            batch_topk = torch.topk(batch_scores, k = topk, dim=1, sorted=True).indices\n",
    "            \n",
    "            batch_gt_array = torch.index_select(gt_mat, 0, batch_seq_indices).to_dense().long()\n",
    "            \n",
    "            num_tests = batch_gt_array.sum(1,keepdims=True)\n",
    "            batch_hits = torch.gather(batch_gt_array, 1, batch_topk)\n",
    "\n",
    "            #select validation user\n",
    "            cond = (num_tests > 0.).flatten()\n",
    "            \n",
    "            batch_recall = _get_recall(batch_hits, num_tests, cond)\n",
    "            recall = torch.cat((recall, batch_recall),0)\n",
    "            \n",
    "            batch_ndcg = _get_ndcg(batch_hits, num_tests, cond)\n",
    "            ndcg = torch.cat((ndcg, batch_ndcg),0)\n",
    "            \n",
    "            batch_mrr = _get_rr(batch_hits, cond)\n",
    "            mrr = torch.cat((mrr, batch_mrr.type('torch.DoubleTensor').cuda()), 0)\n",
    "\n",
    "    return {\"recall\":recall.mean(),\"ndcg\":ndcg.mean(), \"mrr\":mrr.mean() }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
